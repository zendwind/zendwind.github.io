<!DOCTYPE html>
<html lang="zh" prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# object: http://ogp.me/ns/object# article: http://ogp.me/ns/article# profile: http://ogp.me/ns/profile#">
<head>
  <meta charset="utf-8">
  <title>【原】Hadoop小文件存储方案</title>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="keywords" content="hadoop,【原】Hadoop小文件存储方案">
  <meta name="description" content="近来，业务部门因历史原因，希望对现存的图片、对账等历史文件进行改造，由原先的单机存储改成分布式存储便于管理和维护，目前组内也在大力推广HDFS在部门的应用 ，所以在此背景下，调研了目前关于HDFS的文件存储方案，本文会着重从小文件需求入手，分析目前各种现有小文件存储的状况及各自使用的场景。">
   

  <meta name="og:type" content="article">
  <meta name="og:site_name" content="ZendWind的博客">
  <meta name="og:image" content="http://zendwind.com/image/logo.png">
  <meta name="og:title" content="【原】Hadoop小文件存储方案">
  <meta name="og:url" content="http://zendwind.com/2018/05/15/hadoop-small-file-storage/">
  <meta name="og:description" content="近来，业务部门因历史原因，希望对现存的图片、对账等历史文件进行改造，由原先的单机存储改成分布式存储便于管理和维护，目前组内也在大力推广HDFS在部门的应用 ，所以在此背景下，调研了目前关于HDFS的文件存储方案，本文会着重从小文件需求入手，分析目前各种现有小文件存储的状况及各自使用的场景。">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="ZendWind的博客">
  <meta name="twitter:image" content="http://zendwind.com/image/logo.png">
  <meta name="twitter:title" content="【原】Hadoop小文件存储方案">
  <meta name="twitter:creator" content="@JamlingLi">
  <meta name="twitter:description" content="近来，业务部门因历史原因，希望对现存的图片、对账等历史文件进行改造，由原先的单机存储改成分布式存储便于管理和维护，目前组内也在大力推广HDFS在部门的应用 ，所以在此背景下，调研了目前关于HDFS的文件存储方案，本文会着重从小文件需求入手，分析目前各种现有小文件存储的状况及各自使用的场景。">

  <!-- Canonical links -->
  <link rel="canonical" href="http://zendwind.com/2018/05/15/hadoop-small-file-storage/index.html">
  <!-- Alternative links -->
  <!-- CSS and JS-->
  <script src="//cdn.bootcss.com/jquery/2.2.0/jquery.min.js"></script>
<link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.6/css/bootstrap.min.css">
<link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.6/css/bootstrap-theme.min.css">
<script src="//cdn.bootcss.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>
<script src="//cdn.bootcss.com/sidr/2.2.1/jquery.sidr.min.js"></script>
<script src="/js/jquery.bootstrap-autohidingnavbar.min.js"></script>
<script src="/js/script.js"></script>
<script src="/js/lang_select.js"></script>
<link rel="stylesheet" href="//cdn.bootcss.com/sidr/2.2.1/stylesheets/jquery.sidr.dark.min.css">
<link rel="stylesheet" href="//cdn.bootcss.com/highlight.js/9.15.10/styles/github.min.css">
<script src="//cdn.bootcss.com/highlight.js/9.15.10/highlight.min.js"></script>
<link rel="stylesheet" href="//cdn.jsdelivr.net/gh/tonsky/FiraCode@2/distr/fira_code.css">
<script src="//cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js"></script>
<link rel="stylesheet" href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css">
<link rel="stylesheet" href="//cdn.bootcss.com/fancybox/2.1.5/helpers/jquery.fancybox-buttons.css">
<script src="//cdn.bootcss.com/fancybox/2.1.5/helpers/jquery.fancybox-buttons.js"></script>
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.2/animate.min.css">
<link rel="stylesheet" href="/css/nova_font.css">
<link rel="stylesheet" href="/css/bs/nova.css">

  <!-- RSS -->
  <link rel="alternate" href="/atom.xml" title="Zend Wind's Blog">
  <link rel="shortcut icon" href="/image/favicon.ico" type="image/x-icon" />
</head>
<body>
  <!-- header -->
  <header id="body-header">
  <nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top">
    <div class="container container-fluid">
      <!-- Brand and toggle get grouped for better mobile display -->
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse_" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a href="/" id="logo"><img src="/image/logo.png" height="50" alt="logo"></a>
      </div>
      <!-- Collect the nav links, forms, and other content for toggling -->
      <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
        <ul class="nav navbar-nav">
        <li><a href="/" class="main-nav">首页</a></li><li><a href="/p/" class="main-nav">项目</a></li><li><a href="/categories/" class="main-nav">分类</a></li><li><a href="/archives/" class="main-nav">归档</a></li><li><a href="/donate/" class="main-nav">捐赠墙</a></li><li><a href="/about/" class="main-nav">关于</a></li>
        </ul>
        <!-- search input -->
        

<!-- 百度站内搜索（已通过站点验证） -->
<form class="navbar-form navbar-left" role="search"
  action="//search.zendwind.com/cse/search">
  <div class="form-group search">
    <input type="text" name="q" id="bdcsMain" class="form-control primary" aria-label="..." placeholder="搜索">
    <input type="hidden" name="s" value="11812712506721118476">
    <input type="hidden" name="nsid" value="0">
    <!-- 
    <input name="tn" type="hidden" value="SE_zzsearchcode_shhzc78w">
    <input name="cl" type="hidden" value="3">
    <input name="ct" type="hidden" value="2097152">
    <input name="si" type="hidden" value="ieclipse.cn">
    <input name="ie" type="hidden" value="utf-8">
    -->
  </div>
</form>

        <ul class="nav navbar-nav navbar-right">
          <li class="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">语言 <span class="caret"></span></a>
            <ul class="dropdown-menu animated fadeInDown faster">
              <li><a href="/2018/05/15/hadoop-small-file-storage/">zh</a></li>
              
              <li><a href="/en/2018/05/15/hadoop-small-file-storage/">en</a></li>
              
            </ul>
          </li>
        </ul>
      </div>
    </div>
  </nav>
</header>

  <!-- main -->
  
<div class="container container-fluid">
<div class="row">
  <div class="col-sx-12 col-sm-8 col-md-9 col-lg-9">
    
<article class="article post" itemscope="itemscope" itemtype="http://schema.org/Article">
  <header class="article-header">
    <div class="page-path"><span class="post-category"><span class="glyphicon glyphicon-folder-close" aria-hidden="true"></span>当前路径：<a class="category-item" href="/">文章</a><a class="category-item" href="/categories/hadoop/">hadoop</a></span></div>
    <div class="divider"></div>
      <h1 class="article-title" itemprop="name headline"></h1>
    <div class="post-header clearfix">
      <span class="post-date"><span class="hidden-xs icon nova-calendar">发表于</span>
      <time datetime="2018-05-15T15:30:00.000Z" itemprop="datePublished"><time datetime="2018-05-15T15:30:00.000Z">2018-05-15</time></time>
      </span>
      
      <span class="post-share">
        <a href="#share" class="icon nova-share"><span class="hidden-xs">分享</span><span class="jiathis_counter_style"></span></a>
        <a href="#comment" class="icon nova-bubbles"><span class="ds-thread-count" id="changyan_count_unit" data-thread-key="232e5df4cf0e6e325ab564fb945fb0c0"></span><span class="hidden-xs">评论</span></a>
        <!--<a href="#like" class="icon nova-heart2-full"><span class="count" id="changyan_parti_unit"></span><span class="hidden-xs">喜欢</span></a>-->
        <a href="#" class="icon nova-eye"><span class="count lc-count"></span><span class="hidden-xs">次阅读</span></a>
      </span>
    </div>
    <div class="divider"></div>
    <meta content="2018-05-15T15:30:00.000Z" itemprop="datePublished">
  </header>
  <div class="article-content" itemprop="articleBody">
  
    <p>近来，业务部门因历史原因，希望对现存的图片、对账等历史文件进行改造，由原先的单机存储改成分布式存储便于管理和维护，目前组内也在大力推广HDFS在部门的应用 ，所以在此背景下，调研了目前关于HDFS的文件存储方案，本文会着重从小文件需求入手，分析目前各种现有小文件存储的状况及各自使用的场景。<br><a id="more"></a></p>
<h1 id="HDFS总体架构"><a href="#HDFS总体架构" class="headerlink" title="HDFS总体架构"></a>HDFS总体架构</h1><p>在介绍文件存储方案之前，我觉得有必要先介绍下关于HDFS存储架构方面的一些知识，在对架构有初步了解后，才会明白为什么要单独针对小文件展开介绍，小文件存储和其它文件存储区别在什么地方。</p>
<p>这里我只是就Hadoop生态中的存储层展开介绍，对于其它部分本文暂未描述。众所周知，HDFS是目前非常流行的分布式文件存储系统，其逻辑架构如下图所示：<br><img src="/2018/05/15/hadoop-small-file-storage/hadoop_1x_structure.jpg" alt="HDFS架构"></p>
<p>HDFS也是典型的Master/Slave结构，其中，Master相当于Namenode，Slave相当于Datanode。</p>
<p>Namenode 负责元数据管理，维护文件和目录树，响应Client请求；Datanode负责实际数据存储。至于什么是元数据，是怎么管理的，可参考我的另一篇文章<a href="http://km.oa.com/group/11819/articles/show/319776" target="_blank" rel="external">Hadoop的HA机制</a>。</p>
<p>Block是文件块，HDFS中是以Block为单位进行文件的管理的，一个文件可能有多个块，每个块默认是3个副本，这些块分别存储在不同机器上。块与文件之前的映射关系会定时上报Namenode。HDFS中一个块的默认大小是64M，其大小由参数<code>dfs.block.size</code>控制。这里面先引申几个问题出来：</p>
<blockquote>
<ul>
<li><p><strong>问题1：块大小要怎么设置为一个合理值，过大设置和过小设置有什么影响？</strong></p>
</li>
<li><p><strong>问题2：如果一个文件小于所设置的块大小，实际占用空间会怎样？</strong></p>
</li>
<li><p><strong>问题3：一个Namenode最多能管理多少个块，什么时候会达到瓶颈？</strong></p>
</li>
</ul>
</blockquote>
<p>针对这些问题，后面会展开介绍，这里还是先关注下架构方面。针对块方面，有几个单位概念需要弄清楚： <strong>Block、Packet和Chunk</strong>。Block上面有描述，Packet和Chunk如下：</p>
<blockquote>
<ul>
<li><ol>
<li><strong>Packet</strong>: 其比块要小很多，可以理解为Linux操作系统最小盘块概念，一般为64KB，由参数<code>dfs.write.packet.size</code>控制，是client向Datanode写入数据的粒度，即client向Datanode写数据时不是一次以Block为单位写的，而是被分成若干Packet，放入pipeline顺序追加写入到Block中，示意图如下：</li>
</ol>
</li>
</ul>
</blockquote>
<p><img src="/2018/05/15/hadoop-small-file-storage/hdfs_packet.png" alt="packet"></p>
<blockquote>
<ul>
<li><ol>
<li><strong>Chunk</strong>: 比Packet更小，是针对Packet数据校验粒度来设计的，一般是512B,由参数<code>io.bytes.per.checksum</code>控制，同时还带有一个4B的校验值，所以可以认为一个Chunk是516B</li>
</ol>
</li>
</ul>
</blockquote>
<p>上面说到Chunk是针对数据校验的，那一个Packet有多少个chunk校验呢，如果Packet默认是64KB, 那计算公式为：<code>chunk个数=64KB/516B=128</code>。也就是对于一个Packet来说，数据值与校验值比例大概为<strong>128:1</strong>, 对于一个块来说，假设是64M，会对应512KB的校验文件。</p>
<p>Packet的示意图中还一个Header信息，实际存储的是Packet的元数据信息，包括Packet在block中的offset, 数据长度，校验编码等。</p>
<h1 id="HDFS写流程"><a href="#HDFS写流程" class="headerlink" title="HDFS写流程"></a>HDFS写流程</h1><p>了解块相关概念后，再介绍下HDFS的写入流程，如下图所示：</p>
<p><img src="/2018/05/15/hadoop-small-file-storage/hdfs_write_process.png" alt="HDFS写流程"></p>
<blockquote>
<ul>
<li><ol>
<li>client向Namenode发起写文件RPC请求；</li>
</ol>
</li>
<li><ol>
<li>Namenode检查要写的文件是否已存在元数据中，存在则拒绝写入；同时检查写入用户权限，如无权限也拒绝写入；若文件不存在且有权限写入，则Namenode会创建一条文件记录，响应client端允许写入文件；</li>
</ol>
</li>
<li><ol>
<li>client根据文件大小分成若干块，并在Namenode中申请块所存放的Datanode位置，如果是3副本存储，则Namenode会选择3台符合条件的结点放到结点队列中；client实际向Datanode写数据时是以Packet为单位来写到Block的，这里面会涉及两个队列，分别为:<strong>data packet队列</strong>和<strong>ack packet队列</strong>，Packet会同时入数据队列和ack队列；</li>
</ol>
</li>
<li><ol>
<li>通过DataStreamer对象将数据写入pipeline中的第一个Datanode,并依次写入到其它两个结点；当三个结点packet都写成功后，会将packets 从ack queue中删除；</li>
</ol>
</li>
<li><ol>
<li>写操作完成后，client调用close()关闭写操作，并通知Namenode关闭写操作，至此，整个写操作完成。</li>
</ol>
</li>
</ul>
</blockquote>
<p>packet写入流示意图如下所示：</p>
<p><img src="/2018/05/15/hadoop-small-file-storage/hdfs_packet_flow.png" alt="packet流程图"></p>
<h1 id="HDFS读流程"><a href="#HDFS读流程" class="headerlink" title="HDFS读流程"></a>HDFS读流程</h1><p>HDFS的读流程比较简单，流程程如下所示：</p>
<p><img src="/2018/05/15/hadoop-small-file-storage/hdfs_read_process.png" alt="HDFS读流程"></p>
<blockquote>
<ul>
<li><ol>
<li>client 向Namenode发起读文件RPC请求；</li>
</ol>
</li>
<li><ol>
<li>Namenode返回相应block所在datanode的位置信息；</li>
</ol>
</li>
<li><ol>
<li>client通过位置信息调用FSDataInputStream API的Read方法从datanode中并行读取block信息，如图中4和5所示，选择block的其中一副本返回client。</li>
</ol>
</li>
</ul>
</blockquote>
<h1 id="HDFS块信息介绍"><a href="#HDFS块信息介绍" class="headerlink" title="HDFS块信息介绍"></a>HDFS块信息介绍</h1><p>在对HDFS的读写流程有一个基础了解后，下面针对文件块存储相关内容展开介绍。了解块的设计、存储和元数据相关知识对于设计小文件存储方案也至关重要。</p>
<h2 id="HDFS块设计原则"><a href="#HDFS块设计原则" class="headerlink" title="HDFS块设计原则"></a>HDFS块设计原则</h2><p>有人可能会问，集群存储有大文件也有小文件，那块大小该如何设计呢，这里应该要考虑2个准则：</p>
<blockquote>
<ul>
<li><p>1.减少内存占用：对于Namenode来说，单机内存毕竟有限，文件块越多，元数据信息越大，占用内存越多，如果文件数量级很大的话，单机将无法管理；</p>
</li>
<li><p>2.减少硬盘寻道时间： 数据块在硬盘为连续存储，对于普通SATA盘，随机寻址较慢， 如果块设置过小，一个文件的块总数会越多，意味着硬盘寻址时间会加长，自然吞吐量无法满足要求；如果块设置过大，一方面对于普通盘来说IO性能也比较差，加载时会很慢，另一方面，块过大，对于多副本来说，在副本出问题时，系统恢复时间越长。</p>
</li>
</ul>
</blockquote>
<p>所以设置合理的块大小也很重要，一般来说根据集群的需求来设定，比如对于使用到HBase的场景，一般数据量会比较大，块不宜设置太小，参考值一般为128MB或256MB，这样能尽量避免频繁块刷写和块元数据信息的膨胀；对于存储小文件的场景，如图片，块可设置成默认64MB大小，一个块中存储多个图片文件，后面会详细介绍。</p>
<h2 id="HDFS块存储原则"><a href="#HDFS块存储原则" class="headerlink" title="HDFS块存储原则"></a>HDFS块存储原则</h2><p>块在HDFS中是怎么存储的呢，上面有提到多副本机制，即一个块在HDFS中是根据<strong>dfs.replication</strong>参数所设置的值来确定副本数的，默认为3。三个副本是随机存储三台数据结点Datanode上，三个结点的选取遵循机架感知策略，通过<strong>topology.script.file.name</strong>来设置， 如果配置中未配置机架感知，Namenode是无法知道机房网络拓扑，所以会随机选取3台结点进行块存储，如果设置了机架感知，则在存储时会在同机架存储2副本，不同机架放第3个副本，这样一旦一个机架出现问题，还能保证一个副本是可用的。</p>
<p>如果一个文件只有几K，且小于HDFS块大小，实际在HDFS占用的空间会是多少呢？答案是文件大小即为实际占用空间，对于几K的文件实际占用的空间大小也为几K，不会占用一个块空间。</p>
<h2 id="HDFS块元数据信息"><a href="#HDFS块元数据信息" class="headerlink" title="HDFS块元数据信息"></a>HDFS块元数据信息</h2><p>上面提到，在存储的文件数量级很大时，单机Namenode内存消耗会急剧增大，易触发单机瓶颈，那么到底一个Namenode可以管理多少量级的元数据呢，其实这个可以有一个公式来初略估算。这里首先要了解一个概念，元数据包括哪些，正常元数据包括三个部分：<strong>文件、目录和块</strong>。这三部分在元数据中各占用多少空间呢，下面是一个初略的计算：</p>
<blockquote>
<ul>
<li><ol>
<li>单条元数据大小：文件约250B，目录约290B，块约368B(152B+72*副本数3)</li>
</ol>
</li>
<li><ol>
<li>集群元数据总条数：文件数约10000个，目录约5000个，块约20000个</li>
</ol>
</li>
<li><ol>
<li>总占用内存大小： 250B<em>10000+290B</em>5000+368B*20000=10.78M</li>
</ol>
</li>
</ul>
</blockquote>
<p>实际内存消耗会比这多，因为还有其它一些信息需要存储，总体内存消耗可根据上述公式来估算，这样你就知道你集群Namenode能承受多少文件，目录和块元数据信息的存储。也能及时发现内存瓶颈，做到精细化监控运营管理。</p>
<p>上述介绍的三个方面也分别解答了上面提到的三个问题，具体细节这里也不过多展开。下面正式展开对小文件存储方面的介绍</p>
<h1 id="HDFS小文件存储方案"><a href="#HDFS小文件存储方案" class="headerlink" title="HDFS小文件存储方案"></a>HDFS小文件存储方案</h1><p>针对小文件问题，HDFS自身也有考虑这种场景，目前已知的主要有三种方案来实现这种存储，分别如下：</p>
<blockquote>
<ul>
<li>HAR</li>
<li>SequenceFile</li>
<li>CombinedFile</li>
</ul>
</blockquote>
<h2 id="HAR存储方案"><a href="#HAR存储方案" class="headerlink" title="HAR存储方案"></a>HAR存储方案</h2><p>HAR熟称Hadoop归档文件，文件以*.har结尾。归档的意思就是将多个小文件归档为一个文件，归档文件中包含元数据信息和小文件内容，即从一定程度上将Namenode管理的元数据信息下沉到Datanode上的归档文件中，避免元数据的膨胀。</p>
<p>归档文件是怎么生成的呢，主要还是依赖于MapReduce原理将小文件内容进行归并。归档文件的大概组成如下所示：</p>
<p><img src="/2018/05/15/hadoop-small-file-storage/hdfs_har.png" alt="HDFS HAR组成"></p>
<p>图中，左边是原始小文件，右边是har组成。主要包括：<code>_masterindex</code>、<code>_index</code>、<code>part-0...part-n</code>。其中_masterindex和_index就是相应的元数据信息，part-0…part-n就是相应的小文件内容。实际在集群中的存储结构如下：</p>
<p><img src="/2018/05/15/hadoop-small-file-storage/hdfs_har_1.png" alt="HDFS HAR原文件"></p>
<p>通过<code>hadoop archive</code>命令创建归档文件，-archiveName指定文件名, -p指定原文件路径，-r指定要归档的小文件,最后指定hdfs中归档文件存放路径，如下所示：</p>
<p><img src="/2018/05/15/hadoop-small-file-storage/hdfs_har_2.png" alt="HAR创建"></p>
<p>创建后，会在/usr/archive目录下生成test.har目录，这里大家可能会有疑惑，上面不是说Har是一个文件吗，这里怎么又是目录了呢，其实我们所说的归档文件是逻辑上的概念，而实际的har是一个目录，是一个物理存储概念，所以大家只要记住在实际存储时生成的Har实际上是一个目录就行了。这个目录中会存放元数据，实际文件内容。如下图所示，_index文件的每一行表示的是小文件在part开头的映射关系，包括起始和结束位置，是在哪个part文件等，这样在读取har中的小文件时，根据offset位置可直接得到小文件内容，如图part-0文件内容所示：</p>
<p><img src="/2018/05/15/hadoop-small-file-storage/hdfs_har_3.png" alt="HAR结构"></p>
<p>要从HAR读取一个小文件的话，需要用distcp方式，原理也是mapreduce, 指定har路径和输出路径，命令如下：<br><code>hadoop distcp har:///user/archive/test.har/file-1 /tmp/archive/output</code></p>
<p>HAR总体比较简单，它有什么缺点呢?</p>
<blockquote>
<ul>
<li><p>1.archive文件一旦创建不可修改即不能append，如果其中某个小文件有问题，得解压处理完异常文件后重新生成新的archive文件;</p>
</li>
<li><p>2.对小文件归档后，原文件并未删除，需要手工删除;</p>
</li>
<li><p>3.创建HAR和解压HAR依赖MapReduce，查询文件时耗很高;</p>
</li>
<li><p>4.归档文件不支持压缩。</p>
</li>
</ul>
</blockquote>
<h2 id="SequenceFile存储方案"><a href="#SequenceFile存储方案" class="headerlink" title="SequenceFile存储方案"></a>SequenceFile存储方案</h2><p>SequenceFile本质上是一种二进制文件格式，类似key-value存储，通过map/reducer的input/output format方式生成。文件内容由Header、Record/Block、SYNC标记组成，根据压缩的方式不同，组织结构也不同，主要分为Record组织模式和Block组织模式。</p>
<h3 id="Record组织模式"><a href="#Record组织模式" class="headerlink" title="Record组织模式"></a>Record组织模式</h3><p>Record组织模式又包含两种：未压缩状态CompressionType.NONE, 和压缩状态CompressionType.RECORD，未压缩是指不对数据记录进行压缩，压缩态是指对每条记录的value进行压缩，其逻辑结构如下所示：</p>
<p><img src="/2018/05/15/hadoop-small-file-storage/hdfs_sf_record.png" alt="Record模式"></p>
<p>Record结构中包含Record长度、key长度、key值和value值。Sync充斥在Record之间，其作用主要是用于文件位置定位，具体定位方式是：如果提供的文件读取位置不是记录的边界可能在一个Record中间，在实际定位时会定位到所提供位置处之后的第一个Sync边界位置，并从该Sync点往后读相应长度的数据，如果提供的读取位置往后没有Sync边界点，则直接跳转文件末尾；如果提供的文件读取位置是Record边界，则直接从该位置开始读取指定长度的数据。另一种文件定位方式是seek, 这种方式则要求所提供的读取位置是record的边界位置，不然在读取迭代读取下一个位置时会出错。</p>
<h3 id="Block组织模式"><a href="#Block组织模式" class="headerlink" title="Block组织模式"></a>Block组织模式</h3><p>Block组织模式，其压缩态为CompressionType.BLOCK。与Record模式不同的时，Block是以块为单位进行压缩，即将多条Record写到一个块中，当达到一定大小时，对该块进行压缩，很显然，块的压缩效率会比Record要高很多，避免大量消费IO和CPU等资源。其逻辑结构如下：</p>
<p><img src="/2018/05/15/hadoop-small-file-storage/hdfs_sf_block.png" alt="Block模式"></p>
<p>从上图中可看出，组织方式变成了块，一个块中又包含了块的记录数，key长度，key值，value长度，value值。每个块之间也有Sync标记，作用同Record方式。</p>
<p>两中模式中，都有header标记，包含了些如版本信息、KEY类名、VALUE类名、是否压缩标记、是否块压缩标记、编码类、元数据信息和Sync标记，其结构如下：</p>
<p><img src="/2018/05/15/hadoop-small-file-storage/hdfs_sf_header.png" alt="header结构"></p>
<h3 id="SequenceFile示例"><a href="#SequenceFile示例" class="headerlink" title="SequenceFile示例"></a>SequenceFile示例</h3><p>这里以存储5个小的图片文件为例，演示下如何创建SequenceFile。首先将图片文件上传至hdfs的一个目录。</p>
<p><img src="/2018/05/15/hadoop-small-file-storage/hdfs_sf_ex_1.png" alt="图片文件示例"></p>
<p>其次，编写一个MR程序来对上述图片进行转换，将生成的文件存放到/tmp/sequencefile/seq下，MR程序源码在附件SmallFiles.zip中，可自行查看，如下所示：</p>
<p><img src="/2018/05/15/hadoop-small-file-storage/hdfs_sf_ex_2.png" alt="MR程序转换"></p>
<p>转换后，会在/tmp/sequencefile/seq目录生成一个part-r-00000文件，这个文件里面就包含了上述5个图片文件的内容，如下所示：</p>
<p><img src="/2018/05/15/hadoop-small-file-storage/hdfs_sf_ex_3.png" alt="SequenceFile目录结构"></p>
<p>如果要从该SequenceFile中获取所有图片文件，再通过MR程序从文件中将图片文件取出，如下所示：</p>
<p><img src="/2018/05/15/hadoop-small-file-storage/hdfs_sf_ex_4.png" alt="SequenceFile取文件"></p>
<h3 id="SequenceFile优缺点"><a href="#SequenceFile优缺点" class="headerlink" title="SequenceFile优缺点"></a>SequenceFile优缺点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><blockquote>
<ul>
<li>A.支持基于记录或块的数据压缩;</li>
<li>B. 支持splitable,能够作为mr 的输入分片;</li>
<li>C. 不用考虑具体存储格式，写入读取较简单.</li>
</ul>
</blockquote>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><blockquote>
<ul>
<li>A. 需要一个合并文件的过程</li>
<li>B. 依赖于MapReduce</li>
<li>C. 二进制文件，合并后不方便查看</li>
</ul>
</blockquote>
<h2 id="CombinedFile存储方案"><a href="#CombinedFile存储方案" class="headerlink" title="CombinedFile存储方案"></a>CombinedFile存储方案</h2><p>其原理也是基于Map/Reduce将原文件进行转换，通过CombineFileInputFormat类将多个文件分别打包到一个split中，每个mapper处理一个split, 提高并发处理效率，对于有大量小文件的场景，通过这种方式能快速将小文件进行整合。最终的合并文件是将多个小文件内容整合到一个文件中，每一行开始包含每个小文件的完整hdfs路径名，这就会出现一个问题，如果要合并的小文件很多，那么最终合并的文件会包含过多的额外信息，浪费过多的空间，所以这种方案目前相对用得比较少，下面是使用CombineFile的示例：</p>
<figure class="highlight plain"><figcaption><span>ls</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">hbaseadmin@10-163-161-229:~/program/mr/input&gt; touch file-1 file-2 file-3</div><div class="line">hbaseadmin@10-163-161-229:~/program/mr/input&gt; echo &quot;this is file-1&quot; &gt;file-1</div><div class="line">hbaseadmin@10-163-161-229:~/program/mr/input&gt; echo &quot;this is file-2&quot; &gt;file-2</div><div class="line">hbaseadmin@10-163-161-229:~/program/mr/input&gt; echo &quot;this is file-3&quot; &gt;file-3</div><div class="line">hbaseadmin@10-163-161-229:~/program/mr&gt; hadoop fs -put input /tmp/combinefile/</div><div class="line"></div><div class="line">hbaseadmin@10-163-161-229:~/program/mr&gt; hadoop jar SmallFiles.jar  com.fit.dba.mr.util.CombineFileTest /tmp/combinefile/input/ /tmp/combinefile/output</div><div class="line"></div><div class="line">hbaseadmin@10-163-161-229:~/program/mr&gt; hadoop fs -ls /tmp/combinefile/output</div><div class="line">Found 2 items</div><div class="line">-rw-r--r--   1 hbaseadmin supergroup          0 2018-03-25 17:26 /tmp/combinefile/output/_SUCCESS</div><div class="line">-rw-r--r--   1 hbaseadmin supergroup        213 2018-03-25 17:26 /tmp/combinefile/output/part-r-00000</div><div class="line">hbaseadmin@10-163-161-229:~/program/mr&gt; hadoop fs -ls /tmp/combinefile/output/part-r-00000</div><div class="line">Found 1 items</div><div class="line">-rw-r--r--   1 hbaseadmin supergroup        213 2018-03-25 17:26 /tmp/combinefile/output/part-r-00000</div><div class="line">hbaseadmin@10-163-161-229:~/program/mr&gt; hadoop fs -cat /tmp/combinefile/output/part-r-00000</div><div class="line">hdfs://10-163-161-229:9000/tmp/combinefile/input/file-1 this is file-1</div><div class="line">hdfs://10-163-161-229:9000/tmp/combinefile/input/file-2 this is file-2</div><div class="line">hdfs://10-163-161-229:9000/tmp/combinefile/input/file-3 this is file-3</div></pre></td></tr></table></figure>
<p>上述用到的转换程序也在附件CombineFileTest.java中。其优点是适用于处理大量比block小的文件和内容比较少的文件合并，尤其是文本类型/sequencefile等文件合并，其缺点是：如果没有合理的设置maxSplitSize，minSizeNode，minSizeRack，则可能会导致一个map任务需要大量访问非本地的Block造成网络开销，反而比正常的非合并方式更慢。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>上面介绍了三种基于HDFS自身的一些方案，每种方案各有优缺点，其核心思想都是基于map/reduce的方式将多个文件合并成一个文件。在实际使用中，单纯用上述方案还是不太方便，下面简要介绍下目前其它的一些小文件存储方案。</p>
<h1 id="其它小文件存储方案"><a href="#其它小文件存储方案" class="headerlink" title="其它小文件存储方案"></a>其它小文件存储方案</h1><h2 id="基于HBase的小文件存储方案"><a href="#基于HBase的小文件存储方案" class="headerlink" title="基于HBase的小文件存储方案"></a>基于HBase的小文件存储方案</h2><p>HBase我们知道主要是key/value存储结构，一个key对应多个列族的多个列值。从2.0版本开始，HBase多了一个MOB的结构，具体参考HBase-11339。具体是什么概念呢，先来看下示意图：</p>
<p><img src="/2018/05/15/hadoop-small-file-storage/hbase_sf_mob.png" alt="hbase架构"></p>
<p>上图是一个关于HBase的架构图，包含HBase的几个组件master、regionserver、hdfs、hfile等。MOB FILE类似StoreFile, 它作为一个单独的对象存储小文件。MOB具体结构如下所示：</p>
<p><img src="/2018/05/15/hadoop-small-file-storage/hbase_sf_mob_structure.png" alt="mob结构"></p>
<p>MOB是由StoreFile和MOB File共同组成。其中，StoreFile存放的数据和HBase正常存储的数据一样，key/value结构，不过value中存储的是关于MOB文件的长度，存放路径等元数据信息，在MOB File中存储的是具体的MOB文件内容，这样通过StoreFile中的key/value可以找到MOB所存放的文件具体位置和大小，最终得到文件内容。</p>
<p>MOB是怎么设置呢，在创建表时我们指定表的MOB属性，如下所示：<br><code>create &#39;t1&#39;, {NAME =&gt; &#39;f1&#39;, IS_MOB =&gt; true, MOB_THRESHOLD =&gt; 102400}</code></p>
<p>其中，MOB_THRESHOLD表示MOB对象所能存储的文件对象上限阈值，推荐是存储小于10M的文件。对于MOB的表，我们可以手动触发压缩，有<strong>compact_mob</strong>和<strong>major_compact_mob</strong>两种方式。如下所示：<br><code>compact_mob &#39;t1&#39;
compact_mob &#39;t1&#39;,&#39;cf1&#39;
major_compact_mob &#39;t1&#39;
major_compact_mob &#39;t1&#39;,&#39;cf1&#39;</code></p>
<p>MOB的出现大大提高了我们使用HBase存储小文件的效率，这样无须关注底层HDFS是怎么存储的，只要关注上层逻辑即可，HBase的强大优势也能保证存储的高可靠和稳定性，管理也方便。</p>
<h2 id="基于打包构建索引方案"><a href="#基于打包构建索引方案" class="headerlink" title="基于打包构建索引方案"></a>基于打包构建索引方案</h2><p>这种方案是目前兄弟部门正在使用的一个小图片存储方案，也是基于HDFS存储实际图片，基于HBase存储元数据信息。这个方案中，主要也是基于压缩的思路，将多个小图上片压缩成一个tar文件存放至HDFS上，通过HBASE记录文件名和HDFS文件的位置映射关系，架构示意图如下：</p>
<p><img src="/2018/05/15/hadoop-small-file-storage/hbase_sf_tar.png" alt="架构示意图"></p>
<p>其具体思路是：</p>
<blockquote>
<ul>
<li>1.业务部门将图片上传至一个中转机，图片按日期目录存储，不同日期上传的图片放到相应日期目录；</li>
<li>2.定期用脚本去将日期目录打包成tar，一天的图片打包成一个以日期命名的tar, tar文件解压后是直接图片文件，即不带日期那层目录，上传至HDFS指定目录；</li>
<li>3.通过tar文件解析程序获取tar文件中各图片文件在tar中的偏移量和长度，这个解析程序最开始是由国外一个程序员Tom Wallroth写的工具,具体地址可以访问:<a href="http://github.com/devsnd/tarindexer。" target="_blank" rel="external">http://github.com/devsnd/tarindexer。</a> 这个工具可以直接在tar文件上解析tar中各文件的偏移量和长度，很方便。</li>
<li>4.得到图片文件在tar的偏移量和长度后，设计HBase rowkey, 将图片名和tar路径设计到rowkey中，并通过在rowkey前缀加盐方式使rowkey随机散列分布在HBase中，避免热点现象；HBase的value存储的是文件的偏移量和长度。这样HBase中就保存了文件的元数据信息；</li>
<li><ol>
<li>业务方查询具体某个图片时，根据图片的日期和图片名，先计算出HBase rowkey,再去HBase获取该图片的偏移量和长度；通过偏移量和长度通过HDFS的API去读取HDFS的文件。</li>
</ol>
</li>
</ul>
</blockquote>
<h2 id="其它方案对比"><a href="#其它方案对比" class="headerlink" title="其它方案对比"></a>其它方案对比</h2><p>下面针对目前行业内用到的其它一些方案作下对比，如下图所示。</p>
<p><img src="/2018/05/15/hadoop-small-file-storage/sf_compare.png" alt="方案对比"> </p>
<p>总体来说，淘宝的TFS是功能最全的，同时支持大小文件的存储；Ceph也是一种流行的分布式文件存储方案，组内对其调研后感觉比较复杂，不太好管理，不太稳定；FastDFS比较简单，适合存储一些使用场景简单的文件，不太灵活；其它几种没用过，大家可自行上网参阅相关资料。</p>
<h1 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h1><p>本文介绍了关于HDFS小文件存储的方案，不同方案各具特点，在使用时要根据实际业务场景进行设计，对于既要存储大文件又要存储小文件的场景，我建议在上层作一个逻辑处理层，在存储时先判断是大文件还是小文件，再决定是否用打包压缩还是直接上传至HDFS，可借鉴TFS方案。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="hadoop-small-file-storage/hadoop_1x_structure.jpg">1</a> <a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html" target="_blank" rel="external">http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html</a></p>
<h1 id="附件"><a href="#附件" class="headerlink" title="附件"></a>附件</h1><p>关于文章中用的MR转换程序如下所示：<br><a href="https://github.com/ballwql/common-tool/tree/master/java" target="_blank" rel="external">https://github.com/ballwql/common-tool/tree/master/java</a></p>

  
  </div>

  <script src="/js/decrypt.min.js"></script>
  <footer class="article-footer">
    <time class="article-footer-updated" datetime="2020-04-24T02:51:43.090Z" itemprop="dateModified">
    最后更新：2020-04-24
    </time>
    <span itemprop="author publisher" itemscope="itemscope" itemtype="http://schema.org/Organization">
      <meta content="http://zendwind.com" itemprop="url">
      <meta content="ZendWind的博客" itemprop="name">
      <meta content="/image/logo.png" itemprop="logo">
    </span>
    
<a id="share"></a>
<div class="social-share"></div>
<script>
with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='//cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js'];
</script>


  </footer>
</article>

<div class="page-footer">
  <nav><ul class="pager"><li class="previous"><a href="/2018/10/22/en/hbase-api/"><span aria-hidden="true">&larr;</span><span class="hidden-xs">上一页</span></a></li><li class="next"><a href="/2017/11/11/phoenix-introduction/"><span aria-hidden="true">&rarr;</span><span class="hidden-xs">下一页</span></a></li></ul></nav>
  
<!-- Button trigger modal -->
<blockquote class="donate"><!--
  <button type="button" class="btn btn-primary btn-lg" data-toggle="modal" data-target="#DonateModal">
    打赏
  </button>-->
  <p>
  <a href="#" role="button" data-toggle="modal" data-target="#DonateModal">
  <img src="/image/donate_button.png" alt="donate">
  <span>各位看官，鄙人借网络这块宝地在此献丑，望有钱的捧个钱场（打赏任意金额），没钱的捧个人场（分享）</span></a>
  </p>
</blockquote>
<!-- Modal -->
<div class="modal fade" id="DonateModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel">
  <div class="modal-dialog" role="document">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
        <span class="modal-title" id="myModalLabel">打赏</span>
      </div>
      <div class="modal-body"><!--
        <table>
        <thead>
          <th class="text-center">支付宝</th>
          <th class="text-center">微信支付</th>
        </thead>
        <tr>
          <td><img src="/image/donate_alipay.png" alt="使用支付宝扫码打赏" class="img-rounded donate" width="200" height="200"></td>
          <td><img src="/image/donate_wechat.png" alt="使用微信扫码打赏" class="img-rounded donate" width="200" height="200"></td>
        </tr>
        </table>-->
        <div class="container-fluid">
        <div class="row">
        <div class="col-md-6">
          <div class="text-center">
            <span style="display:block;">支付宝</span>
            <img src="/image/donate_alipay.png" alt="使用支付宝扫码打赏" class="donate" />
          </div>
        </div>
        <div class="col-md-6">
          <div class="text-center">
            <span style="display:block;">微信支付</span>
            <img src="/image/donate_wechat.png" alt="使用微信扫码打赏" class="donate" />
          </div>
        </div>
        </div>
        </div>
      </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-default" data-dismiss="modal">关闭</button>
      </div>
    </div>
  </div>
</div>

  <a id="comment"></a>

<script src="//unpkg.com/valine/dist/Valine.min.js">
</script>
<!--PC和WAP自适应版-->
<div id="vcomments" data-sid="232e5df4cf0e6e325ab564fb945fb0c0" ></div>
<script>
    new Valine({
        el: '#vcomments',
        appId: 's7YiMwoKljbjEyiPSekMYxHW-gzGzoHsz',
        appKey: 'QdFr23RGUj3JYo0I4Yi8wuV3',
        path: '232e5df4cf0e6e325ab564fb945fb0c0',
        recordIP: true
    })
</script>



</div>


    
  </div> <!-- end main column  -->
  <!-- aside -->
  <div class="col-sx-12 col-sm-4 col-md-3 col-lg-3">
    <aside>
      <div id="navbar-toc">
      <nav id="toc" class="hidden-print hidden-xs hidden-sm" data-spy="affix">
        <div class="toc-title"><a role="button" data-toggle="collapse" href="#toc-body" aria-expanded="true">
          目录
        </a></div>
        <div id="toc-body" class="in">
        <ul class="nav toc-ul"><li><a href="#HDFS总体架构">HDFS总体架构</a></li><li><a href="#HDFS写流程">HDFS写流程</a></li><li><a href="#HDFS读流程">HDFS读流程</a></li><li><a href="#HDFS块信息介绍">HDFS块信息介绍</a><ul class="nav toc-ul"><li><a href="#HDFS块设计原则">HDFS块设计原则</a></li><li><a href="#HDFS块存储原则">HDFS块存储原则</a></li><li><a href="#HDFS块元数据信息">HDFS块元数据信息</a></li></ul></li><li><a href="#HDFS小文件存储方案">HDFS小文件存储方案</a><ul class="nav toc-ul"><li><a href="#HAR存储方案">HAR存储方案</a></li><li><a href="#SequenceFile存储方案">SequenceFile存储方案</a><ul class="nav toc-ul"><li><a href="#Record组织模式">Record组织模式</a></li><li><a href="#Block组织模式">Block组织模式</a></li><li><a href="#SequenceFile示例">SequenceFile示例</a></li><li><a href="#SequenceFile优缺点">SequenceFile优缺点</a><ul class="nav toc-ul"><li><a href="#优点">优点</a></li><li><a href="#缺点">缺点</a></li></ul></li></ul></li><li><a href="#CombinedFile存储方案">CombinedFile存储方案</a></li><li><a href="#总结">总结</a></li></ul></li><li><a href="#其它小文件存储方案">其它小文件存储方案</a><ul class="nav toc-ul"><li><a href="#基于HBase的小文件存储方案">基于HBase的小文件存储方案</a></li><li><a href="#基于打包构建索引方案">基于打包构建索引方案</a></li><li><a href="#其它方案对比">其它方案对比</a></li></ul></li><li><a href="#总结-1">总结</a></li><li><a href="#参考">参考</a></li><li><a href="#附件">附件</a></li></ul>
        </div>
      </nav>
</div>

      
    </aside>
  </div> <!-- end aside column  -->
</div> <!-- end row -->
</div> <!-- end container -->

  <!-- footer -->
  <footer id="body-footer">
  <div class="divider"></div>
  <div>&nbsp;</div>
  <div class="inner text-center">
    <div id="footer-copyright">
      &copy; 2020 <a href="http://zendwind.com" target="_blank">Wen Qiuliang</a> powered by <a href="http://hexo.io" target="_blank">Hexo</a> Theme <a href="https://github.com/Jamling/hexo-theme-nova" target="_blank">Nova</a><br>
      <!-- Documentation licensed under <a href="http://creativecommons.org/licenses/by/4.0/" target="_blank">CC BY 4.0</a>. -->
    </div>
    <div>
      <a href="http://www.beian.miit.gov.cn" target="_blank"></a>
    </div>
  </div>
</footer>

  <!-- fixed action bar -->
  
  <div class="fab hidden-print" style="bottom: 45px; right: 24px;">
  <!--
    <ul class="top-expand" id="top-expand">
      <li><a class="fab-item large red" href="#top"><i class="icon nova-top"></i></a></li>
      <li><a class="fab-item large yellow " href="//www.jiathis.com/share?uid=2064663" target="_blank"><i class="icon nova-share"></i></a></li>
    </ul>
    <a class="fab-item large red " onclick="$('#top-expand').toggle();">
      <i class="icon nova-list-ul"></i>
    </a>
    -->
    <a class="fab-item large red " href="#top">
      <i class="icon nova-top"></i>
    </a>
  </div>

  <!-- after footer, some 3rd script place here -->
    <script>
    var hljs_labels = {
        left: "代码",
        right: "如下：",
        copy: "复制"
    }
    </script>
    <script src="/js/hljs.js"></script>
    <script src="/js/script.js"></script>
    
    <!-- 安装自动推送JS代码的网页，在页面被访问时，页面URL将立即被推送给百度 -->
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>

    <!-- 新建的搜索框代码，建立使用你自己的代码替换-->
<script>
(function(){document.write(unescape('%3Cdiv id="bdcs"%3E%3C/div%3E'));var bdcs = document.createElement('script');bdcs.type = 'text/javascript';bdcs.async = true;bdcs.src = 'http://znsv.baidu.com/customer_search/api/js?sid=11812712506721118476' + '&plate_url=' + encodeURIComponent(window.location.href) + '&t=' + Math.ceil(new Date()/3600000);var s = document.getElementsByTagName('script')[0];s.parentNode.insertBefore(bdcs, s);})();
</script>

    

<!-- LeanClound官方Javascript SDK -->
<script>
  var page_layout = 'false'
  var lc_debug = false;
  if(typeof AV === 'undefined') {
    $.getScript('//cdn1.lncld.net/static/js/av-min-1.2.1.js',function() {
      lc_debug && console.log('init AV after av.js loaded');
        AV.init({
          appId : 's7YiMwoKljbjEyiPSekMYxHW-gzGzoHsz',
          appKey : 'QdFr23RGUj3JYo0I4Yi8wuV3'
        });
        if (page_layout === 'true') {
          lc_index_views('.card-action', {
            style : 'hidden-xs',
            p : {
              views : '.nova-eye .count'
            }
          })
        }
        lc_page_views();
    });
  }

  var lc_config = {
    pageId : '232e5df4cf0e6e325ab564fb945fb0c0',
    url : '2018/05/15/hadoop-small-file-storage/' || 'http://zendwind.com/2018/05/15/hadoop-small-file-storage/',
    title : '【原】Hadoop小文件存储方案'
  };
  lc_debug && console.log('lcconfig', lc_config);

  var lc_table = 'Counter' || 'Counter';

  function lc_page_views() {
    var query = new AV.Query(lc_table);
    query.select(['-ACL']);
    query.equalTo('pageId', lc_config.pageId);
    query.first({
      success: function(results) {
        // results is an array of AV.Object.
        if (typeof results === 'undefined') {
          insert(results);
          return;
        }
        update(results);
        show(results);
      },
      error: function(error) {
        // error is an instance of AV.Error.
        console.log(error);
      }
    });

    function insert(data) {
      if (!data) {
        lc_debug && console.log('data is null new object');
        var M = AV.Object.extend(lc_table);
        data = new M();
        data.set('views', 1);
      }
      for ( var key in lc_config) {
        data.set(key, lc_config[key]);
      }
      data.save().then(function(data) {
        lc_debug && console.log('created objectId is ' + data.id);
      }, function(error) {
        lc_debug && console.log("create object failed", error);
      });
    }

    function update(data) {
      for ( var key in lc_config) {
        if (key !== 'pageId')
        data.set(key, lc_config[key]);
      }
      lc_debug && console.log("after change,data", data);
      data.increment('views', 1);
      data.save().then(function(data) {
        lc_debug && console.log("update to " + data.get('views'));
      }, function(error) {
        lc_debug && console.log("update object failed", error);
      });
    }

    function show(data) {
      $(".lc-count").html(data.get('views'));
    }
    function show_count(count) {
      $(".lc-count").html(count);
    }
  };

  function lc_index_views() {
    // load views count from leanclound
    // make sure you are created Counter table on leanclound
    function lc_load_views(selector, options) {
      var o = options || {};
      var tkeys = [];
      $(selector).each(function(i) {
        var tkey = $(this).data('tkey');
        tkeys.push(tkey);
      });

      var query = new AV.Query(lc_table);
      query.select([ '-ACL', '-createdAt', '-updatedAt', '-url' ]);
      query.containedIn('pageId', tkeys);
      query.find().then(function(results) {
        $(selector).each(function(i) {
          var tkey = $(this).data('tkey');
          for (var i = 0; i < results.length; i++) {
            var t = results[i];
            if (t.get('pageId') === tkey) {
              var c = t.get('views') + '';
              $(this).find(o.p.views).html(c);
            }
          }
        });
      }, function(error) {
      });
    }

    lc_load_views('.card-action', {
      style : 'hidden-xs',
      p : {
        views : '.nova-eye .count'
      }
    });
  }
</script>

</body>
</html>
